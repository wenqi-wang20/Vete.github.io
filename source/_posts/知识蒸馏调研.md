---
title: 知识蒸馏调研
date: 2022-02-28 17:46:35
tags: [联邦学习，知识蒸馏]
categories: 深度学习 
---

![](https://raw.githubusercontent.com/wenqi-wang20/img/main/blog/20220228191815.png)

Knowledge Distillation: A Survey ：这篇文章系统性的总结了关于知识蒸馏技术目前的所有发展技术，以及未来的展望。

我们按照这个框架的顺序来逐步调研知识蒸馏的技术。

## Section2 Knowledge

![](https://raw.githubusercontent.com/wenqi-wang20/img/main/blog/20220228210726.png)

首先这张图给出了架构，知识蒸馏所蒸馏的知识层面，包括$response-based, \ feature-based, \ relation-based$三种层面。

### Response-Based Knowledge

![](https://raw.githubusercontent.com/wenqi-wang20/img/main/blog/20220228212413.png)

这个可以简单地通过这一张图来说明，student模型通过简单地模仿teacher模型全连接层的logits来学习知识。这里也隐含了所谓的$dark \ knowledge$。因为提取知识的过程必须要依赖最后一层全连接层的结果，所以只能用于 监督学习。

#### weaks

>- 只能用于监督学习
>
>- 无法获取教师模型中期的信息

### Feature-Based Knowledge

主要思想：match the intermediate feature maps

some methods:

- using neuron selectivity transfer to generate "attention map"
- matching the probability distribution in feature space
- using "factors"
- route constraint hint learning , using outputs of hint teacher's hint layer

![](https://raw.githubusercontent.com/wenqi-wang20/img/main/blog/20220228215603.png)

这是基于特征的知识蒸馏的bench流程，以及损失函数
$$
L_{F e a D}\left(f_{t}(x), f_{s}(x)\right)=\mathcal{L}_{F}\left(\Phi_{t}\left(f_{t}(x)\right), \Phi_{s}\left(f_{s}(x)\right)\right)
$$
其中，当教师和学生模型的中间层参数、大小不一致时，需要使用$\phi_t \ \phi_s$转化函数。

#### weaks

>- 如何选择合适的用于指导的隐藏层和被指导的隐藏层？
>- 如何匹配不同大小、参数不同的隐藏层？

### Relation-Based Knowledeg

无论是基于特征的还是基于输出的知识，都需要依赖于某个特定层的output。那么基于relation的知识就是在对不同层之间或者是数据样本之间的关联进行学习。

1. 先是关于不同层之间的联系：

   - 有人提出了FSP矩阵来研究两个特征映射对之间的关联

   - 使用奇异值分解来学习知识

   - 学生模拟教师模型中成对的隐藏特征层之间的信息流

     

     loss function可以定义如下：

     其中一对戴帽子的f分别表示一对来自教师或者是学生模型中的一对特征图。L依然是用来衡量教师模型和学生模型之间的差距。

$$
L_{R e l D}\left(f_{t}, f_{s}\right)=\mathcal{L}_{R^{1}}\left(\Psi_{t}\left(\hat{f}_{t}, \check{f}_{t}\right), \Psi_{s}\left(\hat{f}_{s}, \check{f}_{s}\right)\right)
$$

2. 另一种relation是基于数据样本之间的关系

   - 通过instance relationship graph实例关系图
   - 基于**manfold learning**（多形学习）
   - 将数据样本之间的关系建模为概率分布
   - 基于相关一致性correlation congruence的知识蒸馏，可以学到实例级别的信息和实例之间的关系。

   ![](https://raw.githubusercontent.com/wenqi-wang20/img/main/blog/20220228230753.png)

这是基于数据实例关系的知识蒸馏benchmark
$$
L_{R e l D}\left(F_{t}, F_{s}\right)=\mathcal{L}_{R^{2}}\left(\psi_{t}\left(t_{i}, t_{j}\right), \psi_{s}\left(s_{i}, s_{j}\right)\right)
$$
如上式所示，其中$t$和$s$分别来自老师和学生模型的$feature \ representation$, $\phi$同样衡量两个特征表示之间的相似性，$L$衡量距离。

#### weaks

>- 虽然现在提供了一些基于特征或者数据关系的知识类别，但是如何就关系合理建模依然值得研究。
